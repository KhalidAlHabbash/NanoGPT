{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhalidAlHabbash/NanoGPT/blob/main/NanoGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_3YPTErKKW_",
        "outputId": "81909ab7-a1e3-43e1-d4f5-b752b0587ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-11-11 19:27:32--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8003::154, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt.2’\n",
            "\n",
            "input.txt.2         100%[===================>]   1.06M  3.36MB/s    in 0.3s    \n",
            "\n",
            "2025-11-11 19:27:33 (3.36 MB/s) - ‘input.txt.2’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "batch_size = 64 \n",
        "block_size = 256\n",
        "max_iters = 5000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YYhAdzAJMA_K"
      },
      "outputs": [],
      "source": [
        "# read in input text\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW7HbzljMMyw",
        "outputId": "498cfd78-6b0f-4f90-ae31-b43ee7756a9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ],
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ukWxtIu7MdEo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200019\n"
          ]
        }
      ],
      "source": [
        "# Tiktoken o200k_base tokenizer\n",
        "enc = tiktoken.get_encoding(\"o200k_base\")\n",
        "print(enc.n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GCTt8-3M0ez",
        "outputId": "33cb0826-af9c-4d55-a32e-1dda04dcb9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([297606])\n",
            "tensor([  7127,  84479,    734,  13036,    581,  18988,   1062,   6544,     11,\n",
            "          9598,    668,  10591,    364,   2594,    734, 116872,     11,  10591,\n",
            "           364,   7127,  84479,    734,   3575,    553,    722,  33944,   7542,\n",
            "           316,   1076,   1572,    316,   2079,   1109,   1715,   2594,    734,\n",
            "         80773,     13,  33944,    364,   7127,  84479,    734,   7127,     11,\n",
            "           481,   1761, 149492,    385,   3145, 137928,    382,  20915,  20935,\n",
            "           316,    290,   1665,    364,   2594,    734,   2167,   1761,   1507,\n",
            "            11,    581,   1761,   1507,    364,   7127,  84479,    734,  12845,\n",
            "           765,  15874,   2395,     11,    326,  22782,    679,  33994,    540,\n",
            "          1039,   2316,   3911,    558,   3031,   1507,    261,  75722,   1715,\n",
            "          2594,    734,   3160,    945,  11695,    402,   1507,     26,   1632,\n",
            "           480,    413,   4167,     25,   4194,     11,   4194,   1703,  17422,\n",
            "         84479,    734,   5045,   2195,     11,   1899,  19466,    364,   7127,\n",
            "         84479,    734,   2167,    553,  83982,  12530,  19466,     11,    290,\n",
            "          2506,   2740,  11413,   1899,    558,   4827,  20515,   1512,   2302,\n",
            "          1348,    402,   1481,  61327,    765,     25,    538,   1023,    198,\n",
            "         83527,  14376,    765,    889,    290,   2539,  32844,    536,     11,\n",
            "          2049,    480,   1504,    198,   2078,   8795,    747,     11,    581,\n",
            "          3572,  11915,   1023,  91895,    765,   5396,   1151,    307,   8293,\n",
            "          1023,   2411,    581,    553,   3101,  36203,     25,    290,    505,\n",
            "           934,    436,    484,    198,   2857, 111894,    765,     11,    290,\n",
            "          2817,    328,   1039, 117394,     11,    382,    472,    448,    198,\n",
            "         69660,    316,   5024,   1096,   1043,  50280,     26,   1039,    198,\n",
            "            82,   3299,    766,    382,    261,  11621,    316,   1373,   9024,\n",
            "           765,  72519,    495,    483,    198,    401,    275,  13396,     11,\n",
            "         16466,    581,   5025,    428,   6861,     25,    395,    290,  52901,\n",
            "          1761,    357,    198,     82,  42583,    495,    306,  53080,    395,\n",
            "         19544,     11,    625,    306,  79547,    395,  72519,    364,  17422,\n",
            "         84479,    734,  43762,    481,  18988,   6980,   4372, 149492,    385,\n",
            "          3145, 137928,   1715,   2594,    734, 141068,   2395,   1577,     25,\n",
            "         19016,    261,   1869,   6446,    316,    290,   5355,  59531,    364,\n",
            "         17422,  84479,    734,  49377,    481,   1412,   3581,    501,    853,\n",
            "          4167,    395,   1232,   4931,   1715,   7127,  84479,    734,  29061,\n",
            "          1775,     26,    326,   2023,    413,   3100,    316,   3644,   2395,\n",
            "          1899,    198,  22869,   8024,     11,    889,    484,    501,  15236,\n",
            "         11166,    483,   2447,  15164,    364,  17422,  84479,    734,     45,\n",
            "           356,     11,    889,  10591,    625,  73880,    423,    364,   7127,\n",
            "         84479,    734,     40,   2891,  47329,    481,     11,   1412,    501,\n",
            "         94658,   4167, 125114,     11,    501,   2242,    198,    278,    316,\n",
            "           484,   1268,     25,   5495,  10143,  21675,   2786,  54634,   1966,\n",
            "           665,    413,    198,   3252,    316,   2891,    480,    673,    395,\n",
            "          1232,   4931,    501,   2242,    480,    316,    198,  48576,   1232,\n",
            "         10005,    326,    316,    413,  53958,  15164,     26,   1118,    501,\n",
            "           198,    276,     11,   1952,   7892,    290,  66032,    328,   1232,\n",
            "         74782,    364,  17422,  84479,    734,   4827,    501,   6284,   1652,\n",
            "           306,   1232,   7867,     11,    481,   3527,    261,    198,   2554,\n",
            "           306,   2395,     13,   1608,   2804,    306,    860,   2006,   2891,\n",
            "           501,    382,   8885,    292,    784,    364,   7127,  84479,    734,\n",
            "          3335,    357,   2804,    625,     11,    357,   1309,    625,    413,\n",
            "        190982,    328,  97313,    307,    273,  94658,  92346,     11,    483,\n",
            "         78529,     11,    316,  30796,    306, 100556,    558,   4827,    641,\n",
            "         16513,    553,   1879,     30,    623,   1273,   4307,    293,      6,\n",
            "           290,   5030,    198,    276,  79645,     25,   4436,   5092,    581,\n",
            "           550,   1365,   2105,     30,    316,    290,  61820,   1703,   2594,\n",
            "           734,  37788,     11,   3063,    364,   7127,  84479,    734,  35689,\n",
            "             0,   1218,   5124,   2105,   1715])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize entire input text\n",
        "data = torch.tensor(enc.encode(text), dtype=torch.long)\n",
        "print(data.shape)\n",
        "print(data[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV0GeEiqNd5G",
        "outputId": "8a04355b-a45a-4a5d-aa13-6717d2625c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "267845 29761\n"
          ]
        }
      ],
      "source": [
        "#Split into training and validation sets (90/10)\n",
        "train_percentage = int(0.9 * len(data))\n",
        "train_set = data[:train_percentage]\n",
        "val_set = data[train_percentage:]\n",
        "print(len(train_set), len(val_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb0tOql1OVGk",
        "outputId": "368b89e0-232d-4ef6-edd8-9e3fd458ab40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([  7127,  84479,    734,  13036,    581,  18988,   1062,   6544,     11,\n",
            "          9598,    668,  10591,    364,   2594,    734, 116872,     11,  10591,\n",
            "           364,   7127,  84479,    734,   3575,    553,    722,  33944,   7542,\n",
            "           316,   1076,   1572,    316,   2079,   1109,   1715,   2594,    734,\n",
            "         80773,     13,  33944,    364,   7127,  84479,    734,   7127,     11,\n",
            "           481,   1761, 149492,    385,   3145, 137928,    382,  20915,  20935,\n",
            "           316,    290,   1665,    364,   2594,    734,   2167,   1761,   1507,\n",
            "            11,    581,   1761,   1507,    364,   7127,  84479,    734,  12845,\n",
            "           765,  15874,   2395,     11,    326,  22782,    679,  33994,    540,\n",
            "          1039,   2316,   3911,    558,   3031,   1507,    261,  75722,   1715,\n",
            "          2594,    734,   3160,    945,  11695,    402,   1507,     26,   1632,\n",
            "           480,    413,   4167,     25,   4194,     11,   4194,   1703,  17422,\n",
            "         84479,    734,   5045,   2195,     11,   1899,  19466,    364,   7127,\n",
            "         84479,    734,   2167,    553,  83982,  12530,  19466,     11,    290,\n",
            "          2506,   2740,  11413,   1899,    558,   4827,  20515,   1512,   2302,\n",
            "          1348,    402,   1481,  61327,    765,     25,    538,   1023,    198,\n",
            "         83527,  14376,    765,    889,    290,   2539,  32844,    536,     11,\n",
            "          2049,    480,   1504,    198,   2078,   8795,    747,     11,    581,\n",
            "          3572,  11915,   1023,  91895,    765,   5396,   1151,    307,   8293,\n",
            "          1023,   2411,    581,    553,   3101,  36203,     25,    290,    505,\n",
            "           934,    436,    484,    198,   2857, 111894,    765,     11,    290,\n",
            "          2817,    328,   1039, 117394,     11,    382,    472,    448,    198,\n",
            "         69660,    316,   5024,   1096,   1043,  50280,     26,   1039,    198,\n",
            "            82,   3299,    766,    382,    261,  11621,    316,   1373,   9024,\n",
            "           765,  72519,    495,    483,    198,    401,    275,  13396,     11,\n",
            "         16466,    581,   5025,    428,   6861,     25,    395,    290,  52901,\n",
            "          1761,    357,    198,     82,  42583,    495,    306,  53080,    395,\n",
            "         19544,     11,    625,    306,  79547,    395,  72519,    364,  17422,\n",
            "         84479,    734,  43762,    481])\n"
          ]
        }
      ],
      "source": [
        "print(train_set[:context_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_batch(type):\n",
        "    data = train_set if type == \"train\" else val_set\n",
        "    # Generate random ints to access data (no. of random ints = batch_size)\n",
        "    indices = torch.randint(len(data) - context_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+context_size] for i in indices])\n",
        "    # y is off by 1 so that we can generate multiple training examples from just one input\n",
        "    y = torch.stack([data[i+1:i+context_size+1] for i in indices])\n",
        "    x,y = x.to(device), y.to(device)\n",
        "    return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval() # Preserve computation, no need to calculate gradients\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            x,y = get_batch(split)\n",
        "            logits, loss = model(x,y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "class attentionHead(nn.Module):\n",
        "    \"\"\" Single head of attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False) # Linear layer (x * W(Q,K,V) without the bias)\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False) \n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False) \n",
        "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
        "        self.dropout = nn.Dropout(dropout) # add dropout to prevent overfitting and encourage more robustness\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "\n",
        "        k = self.key(x) # get key vector (B,T, head_size)\n",
        "        q = self.query(x) # get query vector (B,T, head_size)\n",
        "\n",
        "        # compute attention scores\n",
        "        attentionScores = q @ k.transpose(-2,-1) * k.shape[-1] ** -0.5 # --> (B,T,T)\n",
        "        attentionScores = attentionScores.masked_fill(self.tril[:T,:T] == 0, float('-inf')) # Mask future tokens in current context\n",
        "        attentionScores = F.softmax(attentionScores, dim=-1) # apply softmax across each row (represets one token query)\n",
        "        attentionScores = self.dropout(attentionScores)\n",
        "\n",
        "        v = self.value(x) # (B,T,head_size)\n",
        "        out = attentionScores @ v # (B,T,T) @ (B,T,head_size) = (B,T,head_size)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiAttentionHead(nn.Module):\n",
        "    \"\"\" multiple heads of attention in parallel\"\"\"\n",
        "\n",
        "    def __init__(self, head_size, num_heads):\n",
        "        super().__init__()\n",
        "        self.attentionHeads = nn.ModuleList([attentionHead(head_size) for _ in range(num_heads)]) \n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        concat = torch.cat([ah(x) for ah in self.attentionHeads], dim=-1) # concatenate all feature vectors across each attention head\n",
        "        return self.dropout(self.proj(concat)) # mix information across concatenated feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron(nn.Module):\n",
        "    \"\"\" mlp layer of the neural network (linear layer followed by non-linear layer)\"\"\" \n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.mlp(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" one block in a layer (attention  + feed forward (mlp) ) \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_heads):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_heads\n",
        "        self.multiAttentionHeads = MultiAttentionHead(head_size, n_heads)\n",
        "        self.mlp = MultiLayerPerceptron(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.multiAttentionHeads(self.ln1(x)) # maintain residual connections\n",
        "        x = x + self.mlp(self.ln2(x)) # add new result vector of the mlp layer back in to the original vector\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GenerativePretrainedTransformer(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.word_embedding_table = nn.Embedding(enc.n_vocab, n_embd)\n",
        "        self.positional_embedding_table = nn.Embedding(context_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd,n_heads=n_head) for _ in range(n_layer)])\n",
        "        self.final_ln = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, enc.n_vocab)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.word_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.positional_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.final_ln(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "164.553555 M parameters\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# every once in a while evaluate the loss on train and val sets\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m % eval_interval == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28miter\u001b[39m == max_iters - \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         losses = \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# sample a batch of data\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NanoGPT/myenv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mestimate_loss\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eval_iters):\n\u001b[32m      8\u001b[39m     x,y = get_batch(split)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     logits, loss = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     losses[k] = loss.item()\n\u001b[32m     11\u001b[39m out[split] = losses.mean()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NanoGPT/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NanoGPT/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mGeneratePretrainedTransformer.forward\u001b[39m\u001b[34m(self, idx, targets)\u001b[39m\n\u001b[32m     28\u001b[39m x = \u001b[38;5;28mself\u001b[39m.blocks(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m     29\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_ln(x) \u001b[38;5;66;03m# (B,T,C)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B,T,vocab_size)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     33\u001b[39m     loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NanoGPT/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NanoGPT/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/NanoGPT/myenv/lib/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "model = GenerativePretrainedTransformer()\n",
        "m = model.to(device)\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# generate from the model\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPRObwYrWL5F2xEr9VeEc42",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv (3.11.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
